[
  {
    "id": "short_1",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "简述Linux文件权限系统中rwx分别代表什么含义，以及数字表示法如何工作。",
    "referenceAnswer": ""
  },
  {
    "id": "short_2",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释Python中的深拷贝和浅拷贝的区别，并举例说明。",
    "referenceAnswer": "\n浅拷贝：只复制对象本身，不复制嵌套对象（copy.copy()）\n深拷贝：递归复制对象及其所有嵌套对象（copy.deepcopy()）\n示例：列表包含子列表时，浅拷贝后修改子列表会影响原对象"
  },
  {
    "id": "short_3",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "什么是过拟合和欠拟合？在深度学习中如何识别和解决过拟合问题？",
    "referenceAnswer": "\n过拟合：模型在训练集表现好，测试集表现差，记忆了噪声\n欠拟合：模型在训练集和测试集表现都差，未能学习特征\n解决方法：增加数据、正则化、早停、Dropout、简化模型等"
  },
  {
    "id": "short_4",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "简述Transformer模型中的自注意力机制(Self-Attention)是如何工作的。",
    "referenceAnswer": "\n计算每个位置与其他所有位置的注意力权重\n通过Query、Key、Value计算：Attention = softmax(QKᵀ/√d)V\n允许模型关注输入序列中不同位置的相关信息\n解决了RNN的长距离依赖问题"
  },
  {
    "id": "short_5",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释RAG(检索增强生成)系统的基本原理和工作流程。",
    "referenceAnswer": "\n检索器：根据查询从知识库中检索相关文档\n生成器：结合检索到的文档和原始查询生成答案\n工作流程：查询→检索→文档排序→提示构造→生成答案\n优势：知识可更新、减少幻觉、提高准确性"
  },
  {
    "id": "short_6",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释Linux中的软链接和硬链接的区别及其适用场景。",
    "referenceAnswer": "\n软链接是一个独立的文件，包含原文件的路径信息，可以跨文件系统，原文件删除后链接失效。硬链接与原文件共享inode，必须在同一文件系统，原文件删除后链接仍有效。软链接适用于跨文件系统链接，硬链接适用于备份和防止误删。"
  },
  {
    "id": "short_7",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述Python中的垃圾回收机制，特别是引用计数和循环垃圾收集的工作原理。",
    "referenceAnswer": "\nPython使用引用计数和分代垃圾回收。引用计数跟踪对象被引用次数，归零时立即回收。循环垃圾收集处理引用计数无法解决的循环引用问题，通过分代收集策略提高效率。"
  },
  {
    "id": "short_8",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释机器学习中的交叉验证原理及其在模型评估中的重要性。",
    "referenceAnswer": "\n交叉验证将数据集分成k份，轮流用k-1份训练，1份测试，重复k次取平均。重要性在于充分利用数据、减少评估方差、提供更可靠的性能估计。"
  },
  {
    "id": "short_9",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述卷积神经网络中感受野的概念及其在深层网络中的变化规律。",
    "referenceAnswer": "\n感受野是输出特征图上的像素点在输入图像上映射区域的大小。随着网络加深，感受野逐渐增大，深层神经元能看到输入图像的更大范围。"
  },
  {
    "id": "short_10",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释Transformer模型中的残差连接和层归一化如何协同工作以稳定训练过程。",
    "referenceAnswer": "\n残差连接将输入直接加到输出，缓解梯度消失。层归一化对每个样本的特征进行标准化，稳定激活值分布。两者结合使深层网络训练更稳定。"
  },
  {
    "id": "short_11",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述提示词工程中系统提示(System Prompt)和用户提示(User Prompt)的不同作用。",
    "referenceAnswer": "\n系统提示定义模型角色和行为规范，用户提示提供具体任务指令。系统提示设置上下文，用户提示明确任务要求，两者配合引导模型输出。"
  },
  {
    "id": "short_12",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释RAG系统中检索质量对生成结果的影响机制。",
    "referenceAnswer": "\n检索质量直接影响生成器可用的信息质量。高质量检索提供相关文档，生成答案准确；低质量检索引入噪声，导致幻觉或错误答案。"
  },
  {
    "id": "short_13",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述AI Agent中工具调用(Tool Calling)的工作原理及其在复杂任务中的作用。",
    "referenceAnswer": "\n工具调用允许Agent使用外部工具处理任务。Agent分析需求，选择合适工具，传递参数，执行工具，整合结果。这扩展了Agent能力范围，可处理复杂任务。"
  },
  {
    "id": "short_14",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释模型微调中的全参数微调与参数高效微调在计算资源和效果上的权衡。",
    "referenceAnswer": "\n全参数微调效果可能更好但计算成本高；参数高效微调节省计算资源，效果接近全参数微调，更适合资源有限场景。"
  },
  {
    "id": "short_15",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述大模型推理优化中的KV缓存技术原理及其对推理速度的提升机制。",
    "referenceAnswer": "\nKV缓存存储之前时间步的Key和Value向量，避免重复计算。在自回归生成时，只需计算当前时间步的注意力，大幅提升推理速度。"
  },
  {
    "id": "short_16",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释Linux中的管道(|)符号的作用，并举例说明。",
    "referenceAnswer": "\n作用：管道(|)将一个命令的输出作为另一个命令的输入\n优势：组合简单命令完成复杂任务，提高命令行的灵活性和效率\n示例：ps aux | grep python | wc -l统计运行中的Python进程数量"
  },
  {
    "id": "short_17",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述Python中的生成器(Generator)及其优势。",
    "referenceAnswer": "\n定义：生成器是使用yield语句的特殊函数，返回迭代器\n优势：惰性求值，按需生成数据，节省内存空间\n应用：处理大数据流、无限序列、节省内存的场景"
  },
  {
    "id": "short_18",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "比较监督学习、无监督学习和半监督学习的区别。",
    "referenceAnswer": "\n监督学习：使用有标签数据训练，用于分类、回归等任务\n无监督学习：使用无标签数据发现模式，用于聚类、降维等\n半监督学习：结合少量标签数据和大量无标签数据，提高学习效率"
  },
  {
    "id": "short_19",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "解释Transformer模型中的编码器-解码器架构。",
    "referenceAnswer": "\n编码器：将输入序列编码为固定长度的上下文向量\n解码器：基于上下文向量逐步生成输出序列\n应用：机器翻译、文本摘要、语音识别等序列到序列任务"
  },
  {
    "id": "short_20",
    "type": "short_answer",
    "section": "四、简答题",
    "title": "描述大模型微调中的指令微调(Instruction Tuning)过程及其重要性。",
    "referenceAnswer": "\n过程：在指令-响应对数据集上微调预训练模型\n重要性：使模型更好地理解和遵循人类指令\n效果：显著提高模型的指令遵循能力和零样本学习性能"
  }
]